{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import time \n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.algorithms.moo.rnsga2 import RNSGA2\n",
    "from pymoo.algorithms.moo.rnsga3 import RNSGA3\n",
    "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.algorithms.moo.unsga3 import UNSGA3\n",
    "\n",
    "\n",
    "from pymoo.factory import get_reference_directions\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.operators.mutation.pm import PolynomialMutation\n",
    "from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pymoo.core.problem import Problem\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "from multiprocessing.pool import ThreadPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables \n",
    "DATA_PATH = './data/CV_data/eclipse'\n",
    "FEATURES = [\n",
    "  'pre', 'ACD', 'FOUT_avg', 'FOUT_max', 'FOUT_sum', 'MLOC_avg',\n",
    "       'MLOC_max', 'MLOC_sum', 'NBD_avg', 'NBD_max', 'NBD_sum', 'NOF_avg',\n",
    "       'NOF_max', 'NOF_sum', 'NOI', 'NOM_avg', 'NOM_max', 'NOM_sum', 'NOT',\n",
    "       'NSF_avg', 'NSF_max', 'NSF_sum', 'NSM_avg', 'NSM_max', 'NSM_sum',\n",
    "       'PAR_avg', 'PAR_max', 'PAR_sum', 'TLOC', 'VG_avg', 'VG_max', 'VG_sum']\n",
    "TARGET = 'post'\n",
    "DATASET_NAME ='eclipse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers \n",
    "def compute_predictions_probabilities(X,weights) : \n",
    "    ready_X = np.ones((X.shape[0],X.shape[1] + 1 ))\n",
    "    ready_X[:,1:] = X.copy()\n",
    "    weighted_sum = np.dot(ready_X,weights.T)\n",
    "    exp_weighted_sum = np.exp(-1*weighted_sum)\n",
    "    probabilities = 1.0/(exp_weighted_sum + 1.0)\n",
    "    return probabilities\n",
    "\n",
    "def predict(probabilities,threshold): \n",
    "    predictions = probabilities > threshold \n",
    "    return predictions.astype(int)\n",
    "\n",
    "def recall(y_true,predictions): \n",
    "        return recall_score(y_true,predictions)\n",
    "    \n",
    "def cost_predictions(costs,predictions,normalized  = False):\n",
    "    all_costs =  np.sum(predictions*costs)\n",
    "    if normalized : \n",
    "        all_costs = all_costs/np.sum(costs)\n",
    "    return all_costs\n",
    "    \n",
    "def cost_probabilities(costs,probabilities): \n",
    "    return np.sum(probabilities*costs)\n",
    "\n",
    "def benefit(y_true,predictions): \n",
    "    return np.sum(predictions*y_true)\n",
    "\n",
    "def AUC(y_true,probabilities): \n",
    "    return roc_auc_score(y_true, probabilities)\n",
    "\n",
    "def MCC(y_true,predictions): \n",
    "    return matthews_corrcoef(y_true, predictions)\n",
    "\n",
    "def F1(y_true,predictions): \n",
    "    return f1_score(y_true, predictions)\n",
    "\n",
    "def Gmean(y_true,prediction): \n",
    "    return geometric_mean_score(y_true, prediction)\n",
    "\n",
    "def misclassification_cost(y_true,predictions,alpha = 10): \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, predictions).ravel()\n",
    "    return (fp + alpha*fn)/len(predictions)\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def normalize(x) : \n",
    "    return x/np.sum(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnLrWeights(Problem): \n",
    "    def __init__(self,train_data_features,y_true,costs,\n",
    "                 objectives = ['recall','misclassification_cost'],\n",
    "                 lb = -10,ub=10,prediction_threshold = 0.5,**kwargs): \n",
    "        \n",
    "        self.train_data_features_df = train_data_features\n",
    "        nb_variables = len(train_data_features.columns) + 1\n",
    "        temporary = self.train_data_features_df.to_numpy() \n",
    "        self.y_true = y_true\n",
    "        self.costs = costs\n",
    "        self.train_data_features_np = np.ones((len(self.train_data_features_df),nb_variables ))\n",
    "        self.train_data_features_np[:,1:] = temporary\n",
    "        xl = np.array([lb]*nb_variables)\n",
    "        xu = np.array([ub]*nb_variables)\n",
    "        self.prediction_threshold = prediction_threshold\n",
    "        self.objectives = objectives\n",
    "        super().__init__(n_var=nb_variables, n_obj=len(objectives), n_constr=0, xl=xl, xu=xu)\n",
    "        \n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        pool  = ThreadPool(8)\n",
    "        F = pool.map(self.evaluate_one_sol, x)\n",
    "        out['F'] = np.array(F)\n",
    "    def evaluate_one_sol(self,x):\n",
    "        out = []\n",
    "        weighted_sum = np.dot(self.train_data_features_np,x)\n",
    "        weighted_sum = weighted_sum.astype('float64')\n",
    "        exp_weighted_sum = np.exp(-1*weighted_sum)\n",
    "        probabilities = 1.0/(1.0 + exp_weighted_sum)\n",
    "        predictions = probabilities > self.prediction_threshold \n",
    "        predictions = predictions.astype(int)\n",
    "        for objective in self.objectives: \n",
    "            if objective == \"recall\": \n",
    "                out.append(1-self.recall(predictions))\n",
    "            \n",
    "            if objective == \"TNR\": \n",
    "                out.append(1-self.TNR(predictions))\n",
    "\n",
    "            if objective == \"churn_cost_predictions\":\n",
    "                out.append(self.churn_cost_predictions(predictions))\n",
    "            \n",
    "\n",
    "            if objective == \"normalized_churn_cost_predictions\":\n",
    "                out.append(self.churn_cost_predictions(predictions,normalized=True))\n",
    "                \n",
    "            if objective == \"churn_cost_probabilities\":\n",
    "                out.append(self.churn_cost_probabilities(probabilities))\n",
    "                \n",
    "            if objective == \"benefit\":\n",
    "                out.append(sum(self.y_true)-self.benefit(predictions)) \n",
    "            \n",
    "            if objective == \"AUC\":\n",
    "                #print('TIC')\n",
    "                out.append(1 - self.AUC(probabilities)) \n",
    "            \n",
    "            if objective == \"MCC\":\n",
    "                out.append(-1*self.MCC(predictions)) \n",
    "            \n",
    "            if objective == \"F1\":\n",
    "                out.append(-1*self.F1(predictions)) \n",
    "            \n",
    "            if objective == \"Gmean\":\n",
    "                out.append(-1*self.Gmean(predictions)) \n",
    "            \n",
    "            if objective == \"misclassification_cost\": \n",
    "                out.append(self.misclassification_cost(predictions)) \n",
    "\n",
    "            if objective == 'average_churn_recall' : \n",
    "                #print('TOC')\n",
    "                alpha = 0.5 \n",
    "                val = alpha*(1-self.recall(predictions)) + (1 - alpha)*self.churn_cost_predictions(predictions,normalized=True)\n",
    "                out.append(val)\n",
    "\n",
    "            if objective == \"average_AUC_and_recall_churn\" : \n",
    "                alpha = 0.5\n",
    "                recall_churn_val = 0.5*(1-self.recall(predictions)) + 0.5*self.churn_cost_predictions(predictions,normalized=True)\n",
    "                val = alpha*(1 - self.AUC(probabilities)) + (1-alpha)*recall_churn_val\n",
    "                out.append(val)\n",
    "            \n",
    "            if objective == \"average_AUC_recall_churn\" : \n",
    "                val = ((1 - self.AUC(probabilities)) + (1-self.recall(predictions)) + self.churn_cost_predictions(predictions,normalized=True))/3\n",
    "                out.append(val)\n",
    "        return out \n",
    "\n",
    "\n",
    "    def recall(self,predictions): \n",
    "        return recall_score(self.y_true,predictions)\n",
    "    \n",
    "    def churn_cost_predictions(self,predictions,normalized = False): \n",
    "        return cost_predictions(self.costs,predictions,normalized)\n",
    "    \n",
    "    def churn_cost_probabilities(self,probabilities): \n",
    "        return np.sum(probabilities*self.costs)\n",
    "    \n",
    "    def benefit(self,predictions): \n",
    "        return np.sum(predictions*self.y_true)\n",
    "    \n",
    "    def AUC(self,probabilities): \n",
    "        return roc_auc_score(self.y_true, probabilities)\n",
    "    \n",
    "    def MCC(self,predictions): \n",
    "        return matthews_corrcoef(self.y_true, predictions)\n",
    "    \n",
    "    def F1(self,predictions): \n",
    "        return f1_score(self.y_true, predictions)\n",
    "    \n",
    "    def Gmean(self,prediction): \n",
    "        return geometric_mean_score(self.y_true, prediction)\n",
    "    \n",
    "    def misclassification_cost(self,predictions,alpha = 20): \n",
    "        tn, fp, fn, tp = confusion_matrix(self.y_true, predictions).ravel()\n",
    "        return (fp + alpha*fn)/len(predictions)  \n",
    "    def TNR(self, predictions): \n",
    "        return recall_score(self.y_true,predictions,pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_algorithm(algorithm_name,pop_size=400,n_objeectives = 2,\n",
    "                    crossover_op = SBX( prob=0.5, eta=15),\n",
    "                    mutation_op = PolynomialMutation(eta=20,prob = 0.1),\n",
    "                    ref_points = np.array([[0,0]])\n",
    "                    ): \n",
    "    \n",
    "    if algorithm_name == 'NSGA2':\n",
    "        print('running: NSGA2')\n",
    "        algorithm = NSGA2(\n",
    "            pop_size=pop_size,\n",
    "            sampling=FloatRandomSampling(),\n",
    "            crossover=crossover_op,\n",
    "            mutation=mutation_op,\n",
    "        )\n",
    "    \n",
    "    if algorithm_name == 'RNSGA2' : \n",
    "        print('running: RNSGA2')\n",
    "        ref_points = ref_points\n",
    "        print(ref_points)\n",
    "        algorithm = RNSGA2(\n",
    "            pop_size=pop_size,\n",
    "            ref_points= ref_points,\n",
    "            sampling=FloatRandomSampling(),\n",
    "            crossover=crossover_op,\n",
    "            mutation=mutation_op,\n",
    "        )\n",
    "    if algorithm_name == 'RNSGA3' : \n",
    "        print('running: RNSGA3')\n",
    "        ref_points = ref_points\n",
    "        algorithm = RNSGA3(\n",
    "            #pop_size=pop_size,\n",
    "            ref_points= ref_points,\n",
    "            pop_per_ref_point=pop_size,\n",
    "            sampling=FloatRandomSampling(),\n",
    "            crossover=crossover_op,\n",
    "            mutation=mutation_op,\n",
    "        )\n",
    "   \n",
    "    if algorithm_name == 'NSGA3' : \n",
    "        print('Running NSGA3')\n",
    "        ref_dirs = get_reference_directions(\"energy\", n_objeectives, pop_size)\n",
    "        algorithm = NSGA3(\n",
    "            pop_size=pop_size,\n",
    "            sampling=FloatRandomSampling(),\n",
    "            crossover=crossover_op,\n",
    "            mutation=mutation_op,\n",
    "            ref_dirs = ref_dirs\n",
    "        )\n",
    "    \n",
    "    if algorithm_name == 'UNSGA3' : \n",
    "        print('Running NSGA3')\n",
    "        ref_dirs = get_reference_directions(\"energy\", n_objeectives, pop_size)\n",
    "        algorithm = UNSGA3(\n",
    "            pop_size=pop_size,\n",
    "            sampling=FloatRandomSampling(),\n",
    "            crossover=crossover_op,\n",
    "            mutation=mutation_op,\n",
    "            ref_dirs = ref_dirs\n",
    "        )\n",
    "    if algorithm_name == 'GA' : \n",
    "        algorithm = GA(\n",
    "            pop_size=pop_size,\n",
    "            sampling=FloatRandomSampling(),\n",
    "            crossover=crossover_op,\n",
    "            mutation=mutation_op,\n",
    "            eliminate_duplicates=True)\n",
    "    return algorithm\n",
    "\n",
    "\n",
    "def train_MOGA(data,outcome,costs,algorithm,n_gen = 200,\n",
    "                objectives = ['recall','churn_cost_predictions']): \n",
    "    \n",
    "    problem = LearnLrWeights(data, outcome, costs,objectives = objectives)\n",
    "    algorithm = copy.deepcopy(algorithm)    \n",
    "    res = minimize(problem,\n",
    "                    algorithm,\n",
    "                   ('n_gen', n_gen),\n",
    "                   seed=1,\n",
    "                   verbose=True)\n",
    "    X, F = res.opt.get(\"X\", \"F\")\n",
    "    return X,F,res.problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOGA_LR_warapper : \n",
    "    def __init__(\n",
    "                 self,\n",
    "                 params = {},\n",
    "                 objectives = ['recall','misclassification_cost'],\n",
    "                 ) : \n",
    "        \n",
    "        #definition variables \n",
    "        self.X_train = None\n",
    "        self.y_train = None \n",
    "        self.cost_train = None \n",
    "        self.default_params = {\n",
    "            'GA_algorithm' : 'NSGA2',\n",
    "            \"n_gen\" : 500,\n",
    "            'population_size': 200,\n",
    "            'crossover_op' : SBX( prob=0.9, eta=15),\n",
    "            'mutation_op' : PolynomialMutation(eta=20,prob = 1/(len(FEATURES)) ),\n",
    "            'ref_points' : np.array([0.0,0.0]),\n",
    "            'misclassification_cost_coef' : 20 \n",
    "        }\n",
    "        self.actual_params = copy.deepcopy(self.default_params)\n",
    "        self.set_params(params)\n",
    "        #self.prediction_cost_function = prediction_cost_function\n",
    "        #self.preprocessing_function = preprocessing_function\n",
    "        self.objectives = objectives\n",
    "        #state variables \n",
    "        self.is_fit = False\n",
    "        \n",
    "        self.opt_problem = None\n",
    "        self.learned_weights = None\n",
    "        self.weights_objectives = None \n",
    "        self.train_indicies=None \n",
    "        self.validation_indicies = None\n",
    "        self.X_val = None \n",
    "        self.y_val = None  \n",
    "        self.best_model_idx= None\n",
    "        \n",
    "    def fit(self,X,y,costs,train_indicies = None, validation_indicies = None\n",
    "            ) :\n",
    "\n",
    "        self.train_indicies=None \n",
    "        self.validation_indicies = None \n",
    "\n",
    "        self.X_train = X\n",
    "        self.y_train = y \n",
    "        self.train_costs = costs\n",
    "        if not (train_indicies is None) : \n",
    "            \n",
    "            self.train_indicies = train_indicies\n",
    "            self.validation_indicies = validation_indicies\n",
    "            self.X_train = self.X_train.iloc[self.train_indicies]\n",
    "            self.y_train = self.y_train.iloc[self.train_indicies]\n",
    "            self.train_costs = costs[self.train_indicies]\n",
    "\n",
    "            self.X_val = X.iloc[self.validation_indicies]\n",
    "            self.y_val = y.iloc[self.validation_indicies]\n",
    "            self.costs_val = costs[self.validation_indicies]\n",
    "\n",
    "        #X_preprocessed, _= preprocessing_function(X)  \n",
    "        self.ga_algorithm = define_algorithm(algorithm_name= self.actual_params['GA_algorithm'],\n",
    "                            pop_size=self.actual_params['population_size'],\n",
    "                            crossover_op = self.actual_params['crossover_op'],\n",
    "                            mutation_op= self.actual_params['mutation_op'],n_objeectives=len(self.objectives),\n",
    "                            ref_points=None\n",
    "                            ) \n",
    "        final_X_train = self.X_train.copy()    \n",
    "    \n",
    "        self.learned_weights, self.weights_objectives, self.opt_problem = train_MOGA(final_X_train,np.array(self.y_train),np.array(self.train_costs),self.ga_algorithm,self.actual_params['n_gen'], self.objectives)\n",
    "        #print(self.weights_objectives)\n",
    "        self.is_fit = True\n",
    "       \n",
    "        dists = self.weights_objectives[:,1]**2 + self.weights_objectives[:,0]**2\n",
    "        print(dists)\n",
    "        self.best_model_idx = np.argmin(np.array(dists))\n",
    "        \n",
    "    def predict(self,X) : \n",
    "        #X_preprocessed,_ = self.preprocessing_function(X)\n",
    "        probabilities = self.predict_proba(X)\n",
    "        predictions = predict(probabilities,self.opt_problem.prediction_threshold)\n",
    "        #costs = self.prediction_cost_function(X,predictions)\n",
    "        return predictions[:,self.best_model_idx]\n",
    "\n",
    "\n",
    "\n",
    "    def predict_proba(self,X) : \n",
    "        if not(self.is_fit) : \n",
    "            raise NotFittedError('GA is not fitted')\n",
    "        final_X = X.copy()\n",
    "        return compute_predictions_probabilities(final_X,self.learned_weights)\n",
    "\n",
    "    def set_params(self,params) : \n",
    "        for param_name,value in params.items():\n",
    "             self.actual_params[param_name] = value\n",
    "             self.is_fit = False \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "idx = 0\n",
    "n_runs = 100\n",
    "all_results = []\n",
    "for train_file_name in os.listdir(DATA_PATH): \n",
    "    for irun in range(n_runs):\n",
    "        if not('.csv' in train_file_name): \n",
    "            continue\n",
    "        if not('train' in train_file_name): \n",
    "            continue\n",
    "        idx += 1 \n",
    "        train_data_df = pd.read_csv(os.path.join(DATA_PATH, train_file_name)) \n",
    "        test_data_df = pd.read_csv(os.path.join(DATA_PATH, train_file_name.replace('train', 'test')))\n",
    "\n",
    "        X_train, y_train = train_data_df[FEATURES], train_data_df[TARGET]\n",
    "        X_test, y_test = test_data_df[FEATURES], test_data_df[TARGET]\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = copy.deepcopy(X_train)\n",
    "        X_train_scaled[FEATURES] = scaler.fit_transform(X_train[FEATURES])\n",
    "        X_test_scaled = copy.deepcopy(X_test)\n",
    "        X_test_scaled[FEATURES] = scaler.transform(X_test[FEATURES])\n",
    "\n",
    "        MOLR_model = MOGA_LR_warapper()\n",
    "        MOLR_model.fit(X_train_scaled, y_train, costs=None)\n",
    "        y_test_pred = MOLR_model.predict(X_test_scaled)\n",
    "        print('f1:', f1_score(y_test, y_test_pred))\n",
    "        print('G:',geometric_mean_score(y_test, y_test_pred))\n",
    "        print('MCC:',matthews_corrcoef(y_test, y_test_pred))\n",
    "        with open(f'./{train_file_name}_run_{str(irun)}.pkl', 'wb') as f: \n",
    "            pickle.dump(MOLR_model, f)\n",
    "        new_row = {\n",
    "            'algorithm' : 'MOLR',\n",
    "            'file_id' : train_file_name,\n",
    "            'model_id': 'best_performance_model',\n",
    "            'f1' :f1_score(y_test, y_test_pred), \n",
    "            'G' : geometric_mean_score(y_test, y_test_pred), \n",
    "            'MCC': matthews_corrcoef(y_test, y_test_pred),\n",
    "            \"project_name\": train_file_name.split('_')[0]\n",
    "        }\n",
    "        all_results.append(new_row)\n",
    "        if idx % 3 == 0: \n",
    "            pd.DataFrame(all_results).to_csv(f'{DATASET_NAME}_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TSE_R3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
