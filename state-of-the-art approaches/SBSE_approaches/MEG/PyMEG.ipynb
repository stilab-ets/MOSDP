{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import random \n",
    "import copy\n",
    "import numpy as np\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.core.variable import Choice, Variable, Real, Binary, Integer\n",
    "\n",
    "from pymoo.algorithms.base.genetic import GeneticAlgorithm\n",
    "from pymoo.algorithms.soo.nonconvex.ga import FitnessSurvival\n",
    "from pymoo.core.duplicate import ElementwiseDuplicateElimination\n",
    "from pymoo.core.individual import Individual\n",
    "from pymoo.core.infill import InfillCriterion\n",
    "from pymoo.core.population import Population\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.core.variable import Choice, Real, Integer, Binary, BoundedVariable\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.operators.crossover.ux import UX\n",
    "from pymoo.operators.mutation.bitflip import BFM\n",
    "from pymoo.operators.mutation.pm import PM\n",
    "from pymoo.operators.mutation.rm import ChoiceRandomMutation\n",
    "from pymoo.operators.repair.rounding import RoundingRepair\n",
    "from pymoo.operators.selection.rnd import RandomSelection\n",
    "from pymoo.util.display.single import SingleObjectiveOutput\n",
    "from pymoo.operators.crossover.pntx import SinglePointCrossover\n",
    "from pymoo.operators.mutation.bitflip import BitflipMutation\n",
    "from pymoo.core.mixed import MixedVariableMating, MixedVariableGA, MixedVariableSampling, MixedVariableDuplicateElimination\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2, RankAndCrowdingSurvival\n",
    "from pymoo.core.crossover import Crossover\n",
    "from pymoo.core.mutation import Mutation\n",
    "from pymoo.core.duplicate import ElementwiseDuplicateElimination\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "\n",
    "#from mlxtend.classifier import EnsembleVoteClassifier\n",
    "#from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"C:/Users/Motaz/Desktop/work/TSE_R3/PyMEG/data/CV_data/ck\"\n",
    "FEATURES = [\n",
    "    'wmc', 'dit', 'noc', 'cbo', 'rfc', 'lcom', 'ca', 'ce', 'npm', 'lcom3',\n",
    "       'loc', 'dam', 'moa', 'mfa', 'cam', 'ic', 'cbm', 'amc', 'max_cc',\n",
    "       'avg_cc'\n",
    "]\n",
    "TARGET = 'bug'\n",
    "DATASET_NAME ='ck_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDENBClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Bayesian generative classification based on KDE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bandwidth : float\n",
    "        the kernel bandwidth within each class\n",
    "    kernel : str\n",
    "        the kernel name, passed to KernelDensity\n",
    "    \"\"\"\n",
    "    def __init__(self, bandwidth=0.01, kernel='gaussian'):\n",
    "        self.bandwidth = bandwidth\n",
    "        self.kernel = kernel\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.sort(np.unique(y))\n",
    "        \n",
    "        training_sets = [X[y == yi] for yi in self.classes_]\n",
    "       \n",
    "        self.models_ = [KernelDensity(bandwidth=self.bandwidth,\n",
    "                                      kernel=self.kernel).fit(Xi)\n",
    "                        for Xi in training_sets]\n",
    "        \n",
    "        self.logpriors_ = [np.log(Xi.shape[0] / X.shape[0])\n",
    "                           for Xi in training_sets]\n",
    "        return self\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        logprobs = np.array([model.score_samples(X)\n",
    "                             for model in self.models_]).T\n",
    "        result = np.exp(logprobs + self.logpriors_)\n",
    "        #print(result / result.sum(1, keepdims=True))\n",
    "        return np.nan_to_num(result / result.sum(1, keepdims=True))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.classes_[np.argmax(self.predict_proba(X), 1)]\n",
    "    \n",
    "class ArrayVaraiable(Variable): \n",
    "    def __init__(self,length,vtype, **kwargs) -> None: \n",
    "        super().__init__(**kwargs)\n",
    "        self.length = length\n",
    "        self.vtype = copy.deepcopy(vtype)\n",
    "    \n",
    "    def  _sample(self, n):\n",
    "        return np.array([[self.vtype.sample(1) for i in range(self.length)] for j in n])\n",
    "        \n",
    "\n",
    "class BinaryArrayVariable(ArrayVaraiable):\n",
    "     def __init__(self,length,**kwargs):\n",
    "          super().__init__(length=length, vtype=Binary)\n",
    "    \n",
    "class HyperParametersArray(Variable): \n",
    "    def __init__(self, **kwargs) -> None: \n",
    "        super().__init__(**kwargs)\n",
    "        self.variables = [\n",
    "            #NB\n",
    "            Binary(), \n",
    "            Binary(),\n",
    "            Binary(),\n",
    "            #KNN\n",
    "            Integer(bounds= [1, 17]),\n",
    "            Integer(bounds= [1, 17]),\n",
    "            Integer(bounds= [1, 17]),\n",
    "            #SVM\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            #DT \n",
    "            Real(bounds= [0, 0.3]),\n",
    "        ]\n",
    "    def _sample(self, n) :\n",
    "         np.array([\n",
    "            [\n",
    "                variable.sample(1) for variable in self.variables\n",
    "            ]\n",
    "            for _ in range(n)\n",
    "        ])\n",
    "\n",
    "class MEGVariable(Variable): \n",
    "    def __init__(self, bounds, **kwargs):\n",
    "        self.bounds = bounds\n",
    "\n",
    "    def _sample(self, n):\n",
    "        new_vars = [] \n",
    "        for _ in range(n): \n",
    "            \n",
    "            var = {\n",
    "                'ensemble' : [random.choice([0, 1]) for i in range(len(self.bounds))],\n",
    "                'parameters' : [v.sample(1)[0] for v in self.bounds],\n",
    "                'voting_strategy' : random.choice(['majority', 'stacking', 'average_voting', 'weighted_average_voting'])\n",
    "            }\n",
    "            new_vars.append(var)\n",
    "        return np.array(new_vars)\n",
    "\n",
    "class MEGCrossover(Crossover):\n",
    "    def __init__(self,prob=0.95):\n",
    "\n",
    "        # define the crossover: number of parents and number of offsprings\n",
    "        self.proba = prob\n",
    "        super().__init__(2, 2)\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "\n",
    "        # The input of has the following shape (n_parents, n_matings, n_var)\n",
    "        _, n_matings, n_var = X.shape\n",
    "\n",
    "        # The output owith the shape (n_offsprings, n_matings, n_var)\n",
    "        # Because there the number of parents and offsprings are equal it keeps the shape of X\n",
    "        Y = np.full_like(X, None, dtype=object)\n",
    "\n",
    "        # for each mating provided\n",
    "        for k in range(n_matings):\n",
    "\n",
    "            # get the first and the second parent\n",
    "            a, b = X[0, k, 0], X[1, k, 0]\n",
    "\n",
    "            # prepare the offsprings\n",
    "            off_a = copy.deepcopy(a)\n",
    "            off_b = copy.deepcopy(b)\n",
    "            if random.random() < self.proba:\n",
    "                crossover_point = random.choice(range(1, len(a['ensemble'])))\n",
    "                off_a['ensemble'][crossover_point:] = b['ensemble'][crossover_point:]\n",
    "                off_b['ensemble'][crossover_point:] = a['ensemble'][crossover_point:]\n",
    "                off_a['parameters'][crossover_point:] = b['parameters'][crossover_point:]\n",
    "                off_b['parameters'][crossover_point:] = a['parameters'][crossover_point:]\n",
    "            # join the character list and set the output\n",
    "            Y[0, k, 0], Y[1, k, 0] = off_a, off_b\n",
    "        return Y\n",
    "\n",
    "class MEGMutation(Mutation):\n",
    "    def __init__(self, prob = 0.07):\n",
    "        self.bounds = [\n",
    "            Binary(), \n",
    "            Binary(),\n",
    "            Binary(),\n",
    "            #KNN\n",
    "            Integer(bounds= [1, 17]),\n",
    "            Integer(bounds= [1, 17]),\n",
    "            Integer(bounds= [1, 17]),\n",
    "            #SVM\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            #DT \n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "        ]\n",
    "        self.proba = prob\n",
    "        self.stratgy_proba = 0.25\n",
    "        super().__init__()\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "\n",
    "        # for each individual\n",
    "        for i in range(len(X)):\n",
    "\n",
    "            for index in range(len(X[i, 0]['ensemble'])): \n",
    "                r = random.random()\n",
    "                if r < self.proba: \n",
    "                    X[i, 0]['ensemble'][index] = 1 - X[i, 0]['ensemble'][index]\n",
    "                if r < self.proba: \n",
    "                    X[i, 0]['parameters'][index] = self.bounds[index].sample(1)[0]\n",
    "                    \n",
    "            if random.random() < self.stratgy_proba:\n",
    "                X[i, 0]['voting_strategy'] = random.choice(['majority', 'stacking', 'average_voting', 'weighted_average_voting'])\n",
    "        return X\n",
    "\n",
    "class MEGLearner(Problem):\n",
    "    def __init__(self, X, y, test_size, **kwargs):\n",
    "        self.bounds =  [\n",
    "            Binary(),   \n",
    "            Binary(),\n",
    "            Binary(),\n",
    "            #KNN\n",
    "            Integer(bounds= [1, 17]),\n",
    "            Integer(bounds= [1, 17]),\n",
    "            Integer(bounds= [1, 17]),\n",
    "            #SVM\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            #DT \n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "        ]\n",
    "        vars = {\n",
    "            \"MEGVar\": MEGVariable(bounds=self.bounds),\n",
    "        }\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.test_size = test_size\n",
    "        \n",
    "        self.default_models = {\n",
    "            'DT':{\n",
    "                'default' : DecisionTreeClassifier(),\n",
    "                'param' : 'ccp_alpha'\n",
    "            } ,\n",
    "            'NB' : {\n",
    "                'default' : GaussianNB(),\n",
    "                'param' : 'kernel'\n",
    "            },\n",
    "            'SVM' :  {\n",
    "                'default':  SVC(probability=True), \n",
    "                'param' :'cache_size'\n",
    "            }\n",
    "            ,\n",
    "            'KNN' : {\n",
    "                'default': KNeighborsClassifier(n_jobs=-1),\n",
    "                'param': 'n_neighbors'\n",
    "            }\n",
    "        }\n",
    "        super().__init__(vars=vars, n_obj=2,n_ieq_constr=1, **kwargs)\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        pool  = ThreadPool(4)\n",
    "        output = pool.map(self._evaluate_one_sol, x)\n",
    "        F = [o['F'] for o in output]\n",
    "        G = [o['G'] for o in output]\n",
    "        out['F'] = np.array(F)\n",
    "        out['G'] = np.array(G)\n",
    "    def _evaluate_one_sol(self, x):\n",
    "        out = {}\n",
    "        X_train, X_val, y_train, y_val = copy.deepcopy(self.X), copy.deepcopy(self.X),  copy.deepcopy(self.y), copy.deepcopy(self.y)\n",
    "        if not (self.test_size is None):\n",
    "            X_train, X_val, y_train, y_val = train_test_split(self.X, self.y, test_size=self.test_size)\n",
    "        out['F'] = []\n",
    "        out['G'] = []\n",
    "        ready_models =  self.build_models_from_solution(sol=x, out=out)\n",
    "        if (ready_models is None): \n",
    "            print('oups None!!')\n",
    "            return out\n",
    "        ready_models.fit(X_train, y_train)\n",
    "        \n",
    "        mcc_score = matthews_corrcoef(y_val, ready_models.predict(X_val))\n",
    "        models_predictions = self.compute_models_predictions(ready_models, X_val)\n",
    "        diversity = self.compute_deversity_metric(models_predictions, np.array(y_val))\n",
    "        out['F'].append(1 - mcc_score)\n",
    "        out['F'].append(1 - diversity)\n",
    "        out['G'].append(-1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def build_models_from_solution(self, sol, out): \n",
    "        models = []\n",
    "        for index, bit in enumerate(sol[\"MEGVar\"]['ensemble']):\n",
    "            if bit == True:\n",
    "                if  index < 3 and index >= 0:\n",
    "                    \n",
    "                    models.append(('NB', 'NB-' + str(index), self.default_models['NB'], sol[\"MEGVar\"]['parameters'][index]))\n",
    "                elif index >= 3 and index < 6:\n",
    "                    models.append(('KNN', 'KNN-' + str(index - 3), self.default_models['KNN'], sol[\"MEGVar\"]['parameters'][index]))\n",
    "                elif index >= 6 and index < 10: \n",
    "                    models.append(('SVM', 'SVM-' + str(index - 6), self.default_models['SVM'], sol[\"MEGVar\"]['parameters'][index]))\n",
    "                else: \n",
    "                    models.append(('DT', 'DT-' + str(index - 10), self.default_models['DT'], sol[\"MEGVar\"]['parameters'][index]))\n",
    "               \n",
    "        if len(models) <= 1 : \n",
    "            out[\"F\"].append(2)\n",
    "            out[\"F\"].append(1)\n",
    "            out[\"G\"].append(1)\n",
    "            return None \n",
    "        ready_models = self.build_ensemble(models, sol[\"MEGVar\"]['voting_strategy'])\n",
    "        return ready_models\n",
    "    \n",
    "    def build_ensemble(self, models, voting_strategy):\n",
    "        ready_models = []\n",
    "        for model_name, full_model_name, model_data, model_param_value in models: \n",
    "            default_model = copy.deepcopy(model_data['default'])\n",
    "            if model_name == 'NB': \n",
    "                ready_models.append((full_model_name, default_model))\n",
    "            else: \n",
    "                ready_models.append((full_model_name, default_model.set_params(**{model_data['param']: model_param_value})))\n",
    "        ensemble = VotingClassifier(estimators = ready_models, voting='hard', flatten_transform = False, n_jobs=-1)\n",
    "\n",
    "        if voting_strategy == 'average_voting': \n",
    "            ensemble = VotingClassifier(estimators = ready_models, voting='soft', flatten_transform = False, n_jobs=-1)\n",
    "        \n",
    "        if voting_strategy == 'weighted_average_voting':\n",
    "            ensemble = VotingClassifier(estimators = [copy.deepcopy(ready_models[0])] + ready_models, voting='hard', flatten_transform = False, n_jobs=-1)\n",
    "        if voting_strategy == 'stacking': \n",
    "            ensemble = StackingClassifier(estimators = ready_models, final_estimator=ready_models[0][1], n_jobs=-1)\n",
    "        if ensemble is None: \n",
    "            print(ensemble, 'is None!')\n",
    "        return ensemble\n",
    "\n",
    "    def compute_deversity_metric(self, model_predictions, y): \n",
    "        diversities = []\n",
    "        for model_1_index in range(model_predictions.shape[0]): \n",
    "            model_1_predictions = model_predictions[model_1_index,:]\n",
    "            for model_2_index in range(model_1_index + 1, model_predictions.shape[0]): \n",
    "                model_2_predictions = model_predictions[model_2_index,:]\n",
    "                diversities.append(self.compute_diversity(model_1_predictions, model_2_predictions, y))\n",
    "        \n",
    "        return np.mean(diversities)\n",
    "    def compute_diversity(self, classifier_1_predictions, classifier_2_predictions, y):\n",
    "        classifier_1_correctly_classified_instances = np.where(np.equal(classifier_1_predictions, y))[0]\n",
    "        classifier_1_notcorrect_classified_instances = np.where(np.not_equal(classifier_1_predictions, y))[0]\n",
    "\n",
    "        classifier_2_correctly_classified_instances = np.where(np.equal(classifier_2_predictions, y))[0]\n",
    "        classifier_2_notcorrect_classified_instances = np.where(np.not_equal(classifier_2_predictions, y))[0]\n",
    "\n",
    "        N_1_0 = len(set(classifier_1_correctly_classified_instances).intersection(set(classifier_2_notcorrect_classified_instances)))\n",
    "        N_0_1 = len(set(classifier_2_correctly_classified_instances).intersection(set(classifier_1_notcorrect_classified_instances)))\n",
    "\n",
    "        N_1_1 = len(set(classifier_1_correctly_classified_instances).intersection(set(classifier_2_correctly_classified_instances)))\n",
    "        N_0_0 = len(set(classifier_1_notcorrect_classified_instances).intersection(set(classifier_2_notcorrect_classified_instances)))\n",
    "\n",
    "        return (N_1_0 + N_0_1)/(N_1_0 + N_0_1 + N_1_1 + N_0_0)\n",
    "    \n",
    "    def compute_models_predictions(self, ensemble, X): \n",
    "        model_predicion = ensemble.transform(X)\n",
    "        if len(model_predicion.shape)== 2: \n",
    "            return model_predicion.T\n",
    "        else: \n",
    "            predictions = np.argmax(model_predicion, axis=-1)\n",
    "            return predictions\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEGVariable(Variable): \n",
    "    def __init__(self, bounds, **kwargs):\n",
    "        self.bounds = bounds\n",
    "\n",
    "    def _sample(self, n):\n",
    "        new_vars = [] \n",
    "        for _ in range(n): \n",
    "            \n",
    "            var = {\n",
    "                'ensemble' : [random.choice([0, 1]) for i in range(len(self.bounds))],\n",
    "                'parameters' : [v.sample(1)[0] for v in self.bounds],\n",
    "                'voting_strategy' : random.choice(['majority',  'average_voting', 'stacking' , 'weighted_average_voting'])\n",
    "            }\n",
    "            new_vars.append(var)\n",
    "        return np.array(new_vars)\n",
    "\n",
    "class MEGCrossover(Crossover):\n",
    "    def __init__(self,prob=0.95):\n",
    "\n",
    "        # define the crossover: number of parents and number of offsprings\n",
    "        self.proba = prob\n",
    "        super().__init__(2, 2)\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "\n",
    "        # The input of has the following shape (n_parents, n_matings, n_var)\n",
    "        _, n_matings, n_var = X.shape\n",
    "\n",
    "        # The output owith the shape (n_offsprings, n_matings, n_var)\n",
    "        # Because there the number of parents and offsprings are equal it keeps the shape of X\n",
    "        Y = np.full_like(X, None, dtype=object)\n",
    "\n",
    "        # for each mating provided\n",
    "        for k in range(n_matings):\n",
    "\n",
    "            # get the first and the second parent\n",
    "            a, b = X[0, k, 0], X[1, k, 0]\n",
    "\n",
    "            # prepare the offsprings\n",
    "            off_a = copy.deepcopy(a)\n",
    "            off_b = copy.deepcopy(b)\n",
    "            if random.random() < self.proba:\n",
    "                crossover_point = random.choice(range(1, len(a['ensemble'])))\n",
    "                off_a['ensemble'][crossover_point:] = b['ensemble'][crossover_point:]\n",
    "                off_b['ensemble'][crossover_point:] = a['ensemble'][crossover_point:]\n",
    "                off_a['parameters'][crossover_point:] = b['parameters'][crossover_point:]\n",
    "                off_b['parameters'][crossover_point:] = a['parameters'][crossover_point:]\n",
    "            # join the character list and set the output\n",
    "            Y[0, k, 0], Y[1, k, 0] = off_a, off_b\n",
    "        return Y\n",
    "\n",
    "class MEGMutation(Mutation):\n",
    "    def __init__(self, prob = 0.07):\n",
    "        self.bounds = [\n",
    "            Binary(), \n",
    "            Binary(),\n",
    "            Binary(),\n",
    "            #KNN\n",
    "            Integer(bounds= [1, 17]),\n",
    "            Integer(bounds= [1, 17]),\n",
    "            Integer(bounds= [1, 17]),\n",
    "            #SVM\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            #DT \n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "        ]\n",
    "        self.proba = prob\n",
    "        self.stratgy_proba = 0.25\n",
    "        super().__init__()\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "\n",
    "        # for each individual\n",
    "        for i in range(len(X)):\n",
    "\n",
    "            for index in range(len(X[i, 0]['ensemble'])): \n",
    "                r = random.random()\n",
    "                if r < self.proba: \n",
    "                    X[i, 0]['ensemble'][index] = 1 - X[i, 0]['ensemble'][index]\n",
    "                if r < self.proba: \n",
    "                    X[i, 0]['parameters'][index] = self.bounds[index].sample(1)[0]\n",
    "                    \n",
    "            if random.random() < self.stratgy_proba:\n",
    "                X[i, 0]['voting_strategy'] = random.choice(['majority',  'average_voting', 'stacking', 'weighted_average_voting'])\n",
    "        return X\n",
    "\n",
    "\n",
    "class MEGDuplicateElimination(ElementwiseDuplicateElimination):\n",
    "\n",
    "    def is_equal(self, a, b):\n",
    "        if a.X['vote_strategy'] != b.X['vote_strategy']:\n",
    "            return False \n",
    "        for index in range(len(a.X['ensemble'])):\n",
    "            if a.X['ensemble'][index] != b.X['ensemble'][index]:\n",
    "                return False \n",
    "            if a.X['parameters'][index] != b.X['paraneters'][index]:\n",
    "                return False\n",
    "        return True \n",
    "class MixedVariableMating(InfillCriterion):\n",
    "\n",
    "    def __init__(self,\n",
    "                 selection=RandomSelection(),\n",
    "                 crossover=None,\n",
    "                 mutation=None,\n",
    "                 repair=None,\n",
    "                 eliminate_duplicates=True,\n",
    "                 n_max_iterations=100,\n",
    "                 **kwargs):\n",
    "\n",
    "        super().__init__(repair, eliminate_duplicates, n_max_iterations, **kwargs)\n",
    "\n",
    "        if crossover is None:\n",
    "            crossover = {\n",
    "                Binary: UX(),\n",
    "                Real: SBX(),\n",
    "                Integer: SBX(vtype=float, repair=RoundingRepair()),\n",
    "                Choice: UX(),\n",
    "            }\n",
    "\n",
    "        if mutation is None:\n",
    "            mutation = {\n",
    "                Binary: BFM(),\n",
    "                Real: PM(),\n",
    "                Integer: PM(vtype=float, repair=RoundingRepair()),\n",
    "                Choice: ChoiceRandomMutation(),\n",
    "            }\n",
    "\n",
    "        self.selection = selection\n",
    "        self.crossover = crossover\n",
    "        self.mutation = mutation\n",
    "\n",
    "    def _do(self, problem, pop, n_offsprings, parents=False, **kwargs):\n",
    "\n",
    "        # So far we assume all crossover need the same amount of parents and create the same number of offsprings\n",
    "        XOVER_N_PARENTS = 2\n",
    "        XOVER_N_OFFSPRINGS = 2\n",
    "\n",
    "        # the variables with the concrete information\n",
    "        vars = problem.vars\n",
    "\n",
    "        # group all the variables by their types\n",
    "        vars_by_type = {}\n",
    "        for k, v in vars.items():\n",
    "            clazz = type(v)\n",
    "\n",
    "            if clazz not in vars_by_type:\n",
    "                vars_by_type[clazz] = []\n",
    "            vars_by_type[clazz].append(k)\n",
    "\n",
    "        # # all different recombinations (the choices need to be split because of data types)\n",
    "        recomb = []\n",
    "        for clazz, list_of_vars in vars_by_type.items():\n",
    "            if clazz == Choice:\n",
    "                for e in list_of_vars:\n",
    "                    recomb.append((clazz, [e]))\n",
    "            else:\n",
    "                recomb.append((clazz, list_of_vars))\n",
    "\n",
    "        # create an empty population that will be set in each iteration\n",
    "        off = Population.new(X=[{} for _ in range(n_offsprings)])\n",
    "\n",
    "        if not parents:\n",
    "            n_select = math.ceil(n_offsprings / XOVER_N_OFFSPRINGS)\n",
    "            pop = self.selection(problem, pop, n_select, XOVER_N_PARENTS, **kwargs)\n",
    "\n",
    "        for clazz, list_of_vars in recomb:\n",
    "            crossover = self.crossover[clazz]\n",
    "            assert crossover.n_parents == XOVER_N_PARENTS and crossover.n_offsprings == XOVER_N_OFFSPRINGS\n",
    "\n",
    "            _parents = [[Individual(X=np.array([parent.X[var] for var in list_of_vars])) for parent in parents] for\n",
    "                        parents in pop]\n",
    "\n",
    "            _vars = {e: vars[e] for e in list_of_vars}\n",
    "            _xl = np.array([vars[e].lb if hasattr(vars[e], \"lb\") else None for e in list_of_vars])\n",
    "            _xu = np.array([vars[e].ub if hasattr(vars[e], \"ub\") else None for e in list_of_vars])\n",
    "            _problem = Problem(vars=_vars, xl=_xl, xu=_xu)\n",
    "\n",
    "            _off = crossover(_problem, _parents, **kwargs)\n",
    "            mutation = self.mutation[clazz]\n",
    "            _off = mutation(_problem, _off, **kwargs)\n",
    "            for k in range(n_offsprings):\n",
    "                for i, name in enumerate(list_of_vars):\n",
    "                    off[k].X[name] = _off[k].X[i]\n",
    "\n",
    "        return off\n",
    "class MEGLearner(Problem):\n",
    "    def __init__(self, X, y, test_size, **kwargs):\n",
    "        self.bounds =  [\n",
    "            Binary(), \n",
    "            Binary(),\n",
    "            Binary(),\n",
    "            #KNN\n",
    "            Integer(bounds= [1, 17]),\n",
    "            Integer(bounds= [1, 17]),\n",
    "            Integer(bounds= [1, 17]),\n",
    "            #SVM\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            Integer(bounds= [1, 51]),\n",
    "            #DT \n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "            Real(bounds= [0, 0.3]),\n",
    "        ]\n",
    "        vars = {\n",
    "            \"MEGVar\": MEGVariable(bounds=self.bounds),\n",
    "        }\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.test_size = test_size\n",
    "        \n",
    "        self.default_models = {\n",
    "            'DT':{\n",
    "                'default' : DecisionTreeClassifier(),\n",
    "                'param' : 'ccp_alpha'\n",
    "            } ,\n",
    "            'NB' : {\n",
    "                'default' : GaussianNB(),\n",
    "                'param' : 'kernel'\n",
    "            },\n",
    "            'SVM' :  {\n",
    "                'default':  SVC(probability=True), \n",
    "                'param' :'cache_size'\n",
    "            }\n",
    "            ,\n",
    "            'KNN' : {\n",
    "                'default': KNeighborsClassifier(n_jobs=-1),\n",
    "                'param': 'n_neighbors'\n",
    "            }\n",
    "        }\n",
    "        super().__init__(vars=vars, n_obj=2,n_ieq_constr=1, **kwargs)\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        pool  = ThreadPool(4)\n",
    "        output = pool.map(self._evaluate_one_sol, x)\n",
    "        F = [o['F'] for o in output]\n",
    "        G = [o['G'] for o in output]\n",
    "        out['F'] = np.array(F)\n",
    "        out['G'] = np.array(G)\n",
    "    def _evaluate_one_sol(self, x):\n",
    "        out = {}\n",
    "        X_train, X_val, y_train, y_val = copy.deepcopy(self.X), copy.deepcopy(self.X),  copy.deepcopy(self.y), copy.deepcopy(self.y)\n",
    "        if not (self.test_size is None):\n",
    "            X_train, X_val, y_train, y_val = train_test_split(self.X, self.y, test_size=self.test_size)\n",
    "        out['F'] = []\n",
    "        out['G'] = []\n",
    "        ready_models =  self.build_models_from_solution(sol=x, out=out)\n",
    "        if (ready_models is None): \n",
    "            print('oups None!!')\n",
    "            return out\n",
    "        ready_models.fit(X_train, y_train)\n",
    "        \n",
    "        mcc_score = matthews_corrcoef(y_val, ready_models.predict(X_val))\n",
    "        models_predictions = self.compute_models_predictions(ready_models, X_val)\n",
    "        diversity = self.compute_deversity_metric(models_predictions, np.array(y_val))\n",
    "        out['F'].append(1 - mcc_score)\n",
    "        out['F'].append(1 - diversity)\n",
    "        out['G'].append(-1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def build_models_from_solution(self, sol, out): \n",
    "        models = []\n",
    "        for index, bit in enumerate(sol[\"MEGVar\"]['ensemble']):\n",
    "            if bit == True:\n",
    "                if  index < 3 and index >= 0:\n",
    "                    models.append(('NB', 'NB-' + str(index), self.default_models['NB'], sol[\"MEGVar\"]['parameters'][index]))\n",
    "                elif index >= 3 and index < 6:\n",
    "                    models.append(('KNN', 'KNN-' + str(index - 3), self.default_models['KNN'], sol[\"MEGVar\"]['parameters'][index]))\n",
    "                elif index >= 6 and index < 10: \n",
    "                    models.append(('SVM', 'SVM-' + str(index - 6), self.default_models['SVM'], sol[\"MEGVar\"]['parameters'][index]))\n",
    "                else: \n",
    "                    models.append(('DT', 'DT-' + str(index - 10), self.default_models['DT'], sol[\"MEGVar\"]['parameters'][index]))\n",
    "               \n",
    "        if len(models) <= 1 : \n",
    "            out[\"F\"].append(2)\n",
    "            out[\"F\"].append(1)\n",
    "            out[\"G\"].append(1)\n",
    "            return None \n",
    "        ready_models = self.build_ensemble(models, sol[\"MEGVar\"]['voting_strategy'])\n",
    "        return ready_models\n",
    "    \n",
    "    def build_ensemble(self, models, voting_strategy):\n",
    "        ready_models = []\n",
    "        for model_name, full_model_name, model_data, model_param_value in models: \n",
    "            default_model = copy.deepcopy(model_data['default'])\n",
    "            if model_name == 'NB': \n",
    "                if model_param_value == False:\n",
    "                    ready_models.append((full_model_name, default_model))\n",
    "                else: \n",
    "                    ready_models.append((full_model_name, default_model))\n",
    "            else: \n",
    "                ready_models.append((full_model_name, default_model.set_params(**{model_data['param']: model_param_value})))\n",
    "        ensemble = VotingClassifier(estimators = ready_models, voting='hard', flatten_transform = False, n_jobs=-1)\n",
    "        \n",
    "        if voting_strategy == 'weighted_average_voting': \n",
    "            first_model = copy.deepcopy(ready_models[0])\n",
    "            first_model_name, first_model_model = first_model[0], first_model[1]\n",
    "            first_model_name += \"-weighted\"\n",
    "            ensemble = VotingClassifier(estimators = [(first_model_name, first_model_model)] + ready_models, voting='hard', flatten_transform = False, n_jobs=-1)\n",
    "\n",
    "        if voting_strategy == 'average_voting': \n",
    "            first_model = ready_models[0]\n",
    "            ensemble = VotingClassifier(estimators = ready_models, voting='soft', flatten_transform = False, n_jobs=-1)\n",
    "\n",
    "        if voting_strategy == 'stacking': \n",
    "            ensemble = StackingClassifier(estimators = ready_models, final_estimator=ready_models[0][1], n_jobs=-1)\n",
    "        if ensemble is None: \n",
    "            print(ensemble, 'is None!')\n",
    "        return ensemble\n",
    "\n",
    "    def compute_deversity_metric(self, model_predictions, y): \n",
    "        diversities = []\n",
    "        for model_1_index in range(model_predictions.shape[0]): \n",
    "            model_1_predictions = model_predictions[model_1_index,:]\n",
    "            for model_2_index in range(model_1_index + 1, model_predictions.shape[0]): \n",
    "                model_2_predictions = model_predictions[model_2_index,:]\n",
    "                diversities.append(self.compute_diversity(model_1_predictions, model_2_predictions, y))\n",
    "        \n",
    "        return np.mean(diversities)\n",
    "    def compute_diversity(self, classifier_1_predictions, classifier_2_predictions, y):\n",
    "        classifier_1_correctly_classified_instances = np.where(np.equal(classifier_1_predictions, y))[0]\n",
    "        classifier_1_notcorrect_classified_instances = np.where(np.not_equal(classifier_1_predictions, y))[0]\n",
    "\n",
    "        classifier_2_correctly_classified_instances = np.where(np.equal(classifier_2_predictions, y))[0]\n",
    "        classifier_2_notcorrect_classified_instances = np.where(np.not_equal(classifier_2_predictions, y))[0]\n",
    "\n",
    "        N_1_0 = len(set(classifier_1_correctly_classified_instances).intersection(set(classifier_2_notcorrect_classified_instances)))\n",
    "        N_0_1 = len(set(classifier_2_correctly_classified_instances).intersection(set(classifier_1_notcorrect_classified_instances)))\n",
    "\n",
    "        N_1_1 = len(set(classifier_1_correctly_classified_instances).intersection(set(classifier_2_correctly_classified_instances)))\n",
    "        N_0_0 = len(set(classifier_1_notcorrect_classified_instances).intersection(set(classifier_2_notcorrect_classified_instances)))\n",
    "\n",
    "        return (N_1_0 + N_0_1)/(N_1_0 + N_0_1 + N_1_1 + N_0_0)\n",
    "    \n",
    "    def compute_models_predictions(self, ensemble, X): \n",
    "        model_predicion = ensemble.transform(X)\n",
    "        if len(model_predicion.shape)== 2: \n",
    "            return model_predicion.T\n",
    "        else: \n",
    "            predictions = np.argmax(model_predicion, axis=-1)\n",
    "            return predictions\n",
    "                \n",
    "\n",
    "class MixedVariableSampling(Sampling):\n",
    "\n",
    "    def _do(self, problem, n_samples, **kwargs):\n",
    "        V = {name: var.sample(n_samples) for name, var in problem.vars.items()}\n",
    "\n",
    "        X = []\n",
    "        for k in range(n_samples):\n",
    "            X.append({name: V[name][k] for name in problem.vars.keys()})\n",
    "\n",
    "        return X\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main \n",
    "#main\n",
    "idx = 0\n",
    "all_results = []\n",
    "train_size = 0.8\n",
    "n_runs = 10 \n",
    "for i_run in range(5, n_runs):\n",
    "    for train_file_name in os.listdir(DATA_PATH): \n",
    "        if not('.csv' in train_file_name): \n",
    "            continue\n",
    "        if not('train' in train_file_name): \n",
    "            continue\n",
    "       \n",
    "        idx += 1 \n",
    "        print(train_file_name)\n",
    "        train_data_df = pd.read_csv(os.path.join(DATA_PATH, train_file_name)) \n",
    "        test_data_df = pd.read_csv(os.path.join(DATA_PATH, train_file_name.replace('train', 'test')))\n",
    "\n",
    "        X_train, y_train = train_data_df[FEATURES], train_data_df[TARGET]\n",
    "        X_test, y_test = test_data_df[FEATURES], test_data_df[TARGET]\n",
    "        X_val, y_val =  train_data_df[FEATURES],  train_data_df[TARGET]\n",
    "        if not(train_size is None):\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size= train_size)\n",
    "        print('train:',len(X_train))\n",
    "        print('test:',len(X_test))\n",
    "        print(y_train)\n",
    "        MOLR_model = MEGLearner(X_train, y_train,test_size=None)\n",
    "        algorithm = NSGA2(pop_size=500, sampling=MixedVariableSampling(),\n",
    "                    mating=MixedVariableMating(\n",
    "                            eliminate_duplicates=MixedVariableDuplicateElimination(),\n",
    "                            crossover = {MEGVariable:MEGCrossover(prob=1.0)},\n",
    "                            mutation = {MEGVariable:MEGMutation(prob=1.0)}\n",
    "            ),\n",
    "            eliminate_duplicates=MixedVariableDuplicateElimination())\n",
    "        res = minimize(MOLR_model,\n",
    "                    algorithm,\n",
    "                    ('n_gen', 200),\n",
    "                    seed=1,\n",
    "                    verbose=True)\n",
    "        \n",
    "        sols, objes = res.X, res.F\n",
    "        ready_ensembles = []\n",
    "        mccs = []\n",
    "        for sol in sols: \n",
    "            ensemble = MOLR_model.build_models_from_solution(sol=sol, out = {\n",
    "                \"F\":[],\n",
    "                \"G\": []\n",
    "            })\n",
    "            ensemble.fit(X_train, y_train)\n",
    "            ready_ensembles.append(copy.deepcopy(ensemble))\n",
    "            mccs.append(matthews_corrcoef(y_val, ensemble.predict(X_val)))\n",
    "        \n",
    "        best_ensemble_idx = np.argmax(np.array(mccs))\n",
    "        best_ensemble = ready_ensembles[best_ensemble_idx]\n",
    "        best_ensemble.fit(X_train, y_train)\n",
    "        y_test_pred = best_ensemble.predict(X_test)\n",
    "        print('f1:', f1_score(y_test, y_test_pred))\n",
    "        print('G:',geometric_mean_score(y_test, y_test_pred))\n",
    "        print('MCC:',matthews_corrcoef(y_test, y_test_pred))\n",
    "        new_row = {\n",
    "            'algorithm' : 'MEG',\n",
    "            'file_id' : train_file_name,\n",
    "            'model_id': 'best_performance_model',\n",
    "            'run_id': i_run,\n",
    "            'f1' :f1_score(y_test, y_test_pred), \n",
    "            'G' : geometric_mean_score(y_test, y_test_pred), \n",
    "            'MCC': matthews_corrcoef(y_test, y_test_pred),\n",
    "            \"project_name\": train_file_name.split('_')[0]\n",
    "        }\n",
    "        all_results.append(new_row)\n",
    "        if idx % 1 == 0: \n",
    "            pd.DataFrame(all_results).to_csv(f'{DATASET_NAME}_results.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TSE_R3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
