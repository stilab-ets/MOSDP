{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZuGCfXZqYn-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.metrics import specificity_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PK_LXd7qgoC"
   },
   "outputs": [],
   "source": [
    "#data path value. EDIT it to your data path\n",
    "data_path = './validation_data'\n",
    "#edit these variables to include your project and your features \n",
    "projects = {\"ambros\" : [\"mylyn\",\"pde\"],\"eclipse\" : [\"eclipse\"], \"ck\" : [\"camel\",\"poi\",\"prop\",\"synapse\",\"xalan\",\"xerces\",\"lucene\"]}\n",
    "projects_features = {\"ambros\" : [\"numberOfVersionsUntil:\",\"numberOfFixesUntil:\",\"numberOfRefactoringsUntil:\",\"numberOfAuthorsUntil:\",\"linesAddedUntil:\",\"maxLinesAddedUntil:\",\"avgLinesAddedUntil:\",\"linesRemovedUntil:\",\"maxLinesRemovedUntil:\",\"avgLinesRemovedUntil:\",\"codeChurnUntil:\",\"maxCodeChurnUntil:\",\"avgCodeChurnUntil:\",\"ageWithRespectTo:\",\"weightedAgeWithRespectTo:\"],\n",
    "            \"ck\" : [\"wmc\",\"dit\",\"noc\",\"cbo\",\"rfc\",\"lcom\",\"ca\",\"ce\",\"npm\",\"lcom3\",\"loc\",\"dam\",\"moa\",\"mfa\",\"cam\",\"ic\",\"cbm\",\"amc\",\"max_cc\",\"avg_cc\"],\n",
    "            \"eclipse\" : [\"pre\",\"ACD\",\"FOUT_avg\",\"FOUT_max\",\"FOUT_sum\",\"MLOC_avg\",\"MLOC_max\",\"MLOC_sum\",\"NBD_avg\",\"NBD_max\",\"NBD_sum\",\"NOF_avg\",\"NOF_max\",\"NOF_sum\",\"NOI\",\"NOM_avg\",\"NOM_max\",\"NOM_sum\",\"NOT\",\"NSF_avg\",\"NSF_max\",\"NSF_sum\",\"NSM_avg\",\"NSM_max\",\"NSM_sum\",\"PAR_avg\",\"PAR_max\",\"PAR_sum\",\"TLOC\",\"VG_avg\",\"VG_max\",\"VG_sum\"]\n",
    "            }\n",
    "outcome =  {\"ck\" : \"bug\",\"ambros\" : \"bugs\",\"eclipse\" : \"post\"}  \n",
    "#Edit these variables to use SMOTE or parameter tunning\n",
    "apply_smote = True \n",
    "apply_parameter_tunning = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3w_9a6qPC9Mf"
   },
   "outputs": [],
   "source": [
    "#models and their grid\n",
    "models = {\"DT\" : DecisionTreeClassifier(),\n",
    "          \n",
    "        \n",
    "          \"NB\" :GaussianNB(),\n",
    "         \n",
    "          \"LR\" :  LogisticRegression(max_iter=10000),\n",
    "          \"SVM\" :  SVC(),\n",
    "          \"RF\" :  RandomForestClassifier()\n",
    "          }\n",
    "tune_params = {\n",
    "    'DT' : {'ccp_alpha' : [0.0001,0.001,0.01,0.1,0.5],'max_depth' : [5,7,10,15]}, \n",
    "    'RF' : {'n_estimators' : [10,30,50,80,100,150,200,250,300,350,400,450,500],'max_depth' : [5,7,10,15]},\n",
    "    'SVM' : {'gamma' : [0.1,0.3,0.5,0.7,0.9],'C' : [0.25,0.5,1,2,4]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzckQOSqI6iq"
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns = [\"algorithm\",\"model_id\",\"file_id\",\"train_or_test\",\"project_name\",\"f1\",\"tpr\",\"tnr\",\"G\",\"precision\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qzDNhgxOJf9N",
    "outputId": "6415d782-1f0e-483a-eba2-cd9ade903c4d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#main loop\n",
    "for i,file_name in enumerate(os.listdir(data_path)) : \n",
    "  if \"train\" in file_name : \n",
    "    print(\"working on : \",file_name)\n",
    "    models = {\"DT\" : DecisionTreeClassifier(),\n",
    "          \n",
    "        \n",
    "          \"NB\" :GaussianNB(),\n",
    "         \n",
    "          \"LR\" :  LogisticRegression(max_iter=10000),\n",
    "          \"SVM\" :  SVC(),\n",
    "          \"RF\" :  RandomForestClassifier()\n",
    "          }\n",
    "\n",
    "    row = {} \n",
    "    train_data = pd.read_csv(os.path.join(data_path,file_name))\n",
    "    test_data = pd.read_csv(os.path.join(data_path,file_name.replace(\"train\",\"test\")))\n",
    "    project_name = file_name.replace(\".csv\",\"\").split(\"_\")[0]\n",
    "    project_id = \"\"\n",
    "    row[\"file_id\"] = file_name\n",
    "    row[\"projec_name\"] = project_name\n",
    "    row[\"model_id\"] = \"best_model_performance\"\n",
    "    for project in projects : \n",
    "      for pnames in projects[project] : \n",
    "        if pnames in project_name :\n",
    "          project_id = project \n",
    "          break\n",
    "    features = projects_features[project_id]\n",
    "    output_variable = outcome[project_id]\n",
    "    for j,model_id in enumerate(models) : \n",
    "      print(model_id)\n",
    "      \n",
    "      if apply_smote : \n",
    "          sm = SMOTE(random_state=i*(j+1))\n",
    "          X_res, y_res = sm.fit_resample(train_data.loc[:,features].values, train_data.loc[:,output_variable].values)\n",
    "      else : \n",
    "          X_res = train_data.loc[:,features].values \n",
    "          y_res = train_data.loc[:,output_variable].values \n",
    "      row[\"algorithm\"]= model_id\n",
    "      model = models[model_id] \n",
    "      if apply_parameter_tunning : \n",
    "          if model_id in tune_params : \n",
    "              #print('pm is applied')\n",
    "              rf_random = GridSearchCV(estimator = model, param_grid = tune_params[model_id], cv = 3, verbose=2, n_jobs = -1)\n",
    "              rf_random.fit(X_res,y_res)\n",
    "              model = rf_random.best_estimator_\n",
    "      model.fit(X_res,y_res)\n",
    "      \n",
    "      y_train_predict = model.predict(train_data[features])\n",
    "      y_test_predict = model.predict(test_data[features])\n",
    "\n",
    "      row[\"train_or_test\"] = \"train\"\n",
    "\n",
    "      row[\"f1\"]= f1_score(train_data[output_variable],y_train_predict)\n",
    "      row[\"precision\"]= precision_score(train_data[output_variable],y_train_predict)\n",
    "      row[\"tpr\"]=recall_score(train_data[output_variable],y_train_predict)\n",
    "      row[\"G\"]=geometric_mean_score(train_data[output_variable],y_train_predict)\n",
    "      row[\"tnr\"]=specificity_score(train_data[output_variable],y_train_predict)\n",
    "\n",
    "      df_results = df_results.append(row,ignore_index=True)      \n",
    "      row[\"train_or_test\"] = \"test\"\n",
    "\n",
    "      row[\"f1\"]= f1_score(test_data[output_variable],y_test_predict)\n",
    "      row[\"precision\"]= precision_score(test_data[output_variable],y_test_predict)\n",
    "      row[\"tpr\"]=recall_score(test_data[output_variable],y_test_predict)\n",
    "      row[\"G\"]=geometric_mean_score(test_data[output_variable],y_test_predict)\n",
    "      row[\"tnr\"]=specificity_score(test_data[output_variable],y_test_predict)\n",
    "\n",
    "      df_results = df_results.append(row,ignore_index=True)   \n",
    "\n",
    "df_results.to_excel( \"results.xlsx\",index=False)\n",
    "      \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML for sdp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
